---
title: "analysis_stable"
output: 
  html_document:
    toc: true
    toc_float: true
    df_print: paged
date: "`r substr(Sys.time(), 1, 10)`"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.align = "center",
  fig.retina = 2,
  fig.width = 10,
  cache.lazy = FALSE
  )

library(tidyverse)
library(stringr)
library(viridis)
library(vctrs)

library(DT)

library(fst)

library(bench)

source("insights.R", local = knitr::knit_global())
```

All insights about eval calls are to put here, after the computations are stabilized (so use another notebook to explore).


# Setup

```{r eval_calls_file}
eval_calls_file <- "/var/lib/R/project-evalR/run/package-evals-traced-all.1/calls.fst"
```


```{r load_file}
eval_calls <- read_fst(eval_calls_file)
eval_calls <- as_tibble(eval_calls) 
```

```{r resolve_types}
eval_calls <- eval_calls %>% resolve_sexp_name(expr_expression_type) %>% 
                             resolve_sexp_name(expr_resolved_type) %>%
                             resolve_sexp_name(enclos_type) %>%
                             resolve_sexp_name(envir_type)
```


# Usage metrics


## Number of `eval`


For the number of call sites, we either use the `srcref` when there is one. When there is not (such as in *base*), we use a combination of `caller_package` and `caller_function`.

```{r}
nb_call_sites <- eval_calls %>% select(eval_call_srcref) %>% n_distinct(na.rm = TRUE)  + eval_calls %>% filter(is.na(eval_call_srcref)) %>% select(caller_package, caller_function)%>% n_distinct()
```

<details>
  <summary>More information about when there is no <code>srcref</code> </summary>
  
  We assume that:
  
  - the combination `caller_package` and `caller_function` is unique
  - there is only one call site per such `caller_function`
  
  It means that we get a lower bound.
</details> 

There are `r nb_call_sites` different `eval` call sites.

### Per package

```{r eval_call_sites_base}
eval_calls %>% filter(caller_package == "base") %>% select(caller_function) %>% n_distinct(na.rm = TRUE)
```

<details>
  <summary> Comparing with <code>grep</code></summary>
  Grepping *base* to find eval call sites yields 40 `eval` call sites.
</details>

```{r eval_call_sites_per_package}
eval_calls %>% filter(caller_package != "base") %>% group_by(caller_package) %>% summarize(nb_call_sites =  n_distinct(eval_call_srcref, na.rm = TRUE)) %>% arrange(desc(nb_call_sites))
```

We probably forget the generated ones here, but should we count them in the _call sites_?

## Number of calls to `eval`

```{r}
nb_eval_calls <- eval_calls %>% nrow()
```

There are `r nb_eval_calls` eval calls.


```{r nb_eval_calls_per_package}
nb_eval_calls_per_package <- eval_calls %>% group_by(caller_package) %>% summarise(nb_eval_calls_package = n(), per_cent = nb_eval_calls_package / nb_eval_calls * 100) %>% arrange(desc(nb_eval_calls_package))
```

*base* has the highest number of eval calls, i.e. `r nb_eval_calls_per_package["per_cent", 1]`% of them.

  
```{r}
nb_eval_calls_per_package  %>% datatable()
```


## Size of expressions as arguments to `eval`

```{r expression_size}

eval_calls <- eval_calls %>% mutate(expr_expression_size = str_length(expr_expression), expr_resolved_size = str_length(expr_resolved), envir_expression_size = str_length(envir_expression), enclos_expression_size = str_length(enclos_expression))

```


```{r}
eval_calls %>% ggplot() +
  geom_histogram(aes(x = expr_expression_size), na.rm = TRUE, binwidth=1) +
  scale_x_log10() +  scale_y_sqrt()
```

If we remove the outliers:
```{r}
eval_calls %>% filter(expr_expression_size < 25000) %>% ggplot() +
  geom_histogram(aes(x = expr_expression_size), na.rm = TRUE, binwidth=2)  + scale_x_sqrt() +  scale_y_sqrt() 
```


<details>
  <summary>More details</summary>
  
  
What about the code size of expressions that seem to be generated?
An approximation of *generated* will be no `srcref` and not in `base`.


```{r code_size_srcref}
eval_calls %>% filter(is.na(eval_call_srcref), caller_package != "base") %>% ggplot() +
  geom_histogram(aes(x = expr_expression_size), na.rm = TRUE, binwidth=1) + scale_x_sqrt() + scale_y_sqrt()
```

And the average size per package:
```{r average_size_package}
eval_calls %>% group_by(caller_package) %>% summarize(average_expr_size = mean(expr_expression_size, na.rm = TRUE)) %>% arrange(desc(average_expr_size))
```

If we look at the maxima, the largest ones are in *base*:
```{r max_size_package}
eval_calls %>% group_by(caller_package) %>% summarize(max_expr_size = max(expr_expression_size, na.rm = TRUE)) %>% arrange(desc(max_expr_size))
```

</details>



## Amount of computations performed in `eval`

## Aliases of `eval`


# A taxonomy of `eval`

## The operation mix

## Scope (environments)


## Patterns

## Provenance

Some `eval` result from parsing text (directly or through a file) with `parse`.

```{r eval_from_parse}
parsed_evals <- eval_calls %>% filter(!is.na(expr_parsed))
```

There are `r parsed_evals %>% nrow()` such calls, `r (parsed_evals %>% nrow()) / nb_eval_calls * 100`%.

```{r, hide = TRUE}
nb_parsed_call_sites <- nb_eval_call_sites(parsed_evals)
```

In terms of call sites, there are `r nb_parsed_call_sites` i.e. `r nb_parsed_call_sites / nb_call_sites * 100`.

<details>
  <summary>More about <code>parse</code> </summary>
  
  We can differentiate further the provenance, i.e. whether the evaluated string comes from `file` or from `text`.
  
```{r parsed_evals_source}
parsed_evals <- parsed_evals %>% mutate(parse_args = map(expr_expression, function_arguments)) %>% unnest_wider(parse_args, names_repair = "unique")

```


  
</details>

## Consistence

# Other faces of `eval`

# Case studies